{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/amadeo-tunyi/Learning-Vector-Quantization/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LVQ.snpc import SNPC\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_d = pd.read_csv('LVQ/data/new_adult.csv', index_col = [0])\n",
    "income = a_d['income']\n",
    "inc = pd.DataFrame(np.array(income), columns= ['labels'])\n",
    "a_d.drop('income', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(a_d)[:600], np.array(inc)[:600], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......73.87, loss......0.2437\n",
      "Training Progress:  10%|█         | 10/100 [00:01<00:11,  7.53it/s]snpc.py:238 - Acc.......71.97, loss......0.2017\n",
      "Training Progress:  20%|██        | 20/100 [00:02<00:08,  8.95it/s]snpc.py:238 - Acc.......70.44, loss......0.1905\n",
      "Training Progress:  30%|███       | 30/100 [00:03<00:08,  7.86it/s]snpc.py:238 - Acc.......69.94, loss......0.1826\n",
      "Training Progress:  40%|████      | 40/100 [00:04<00:06,  9.02it/s]snpc.py:238 - Acc.......69.68, loss......0.1773\n",
      "Training Progress:  50%|█████     | 50/100 [00:06<00:05,  8.93it/s]snpc.py:238 - Acc.......69.43, loss......0.1727\n",
      "Training Progress:  60%|██████    | 60/100 [00:07<00:04,  8.96it/s]snpc.py:238 - Acc.......69.17, loss......0.1693\n",
      "Training Progress:  70%|███████   | 70/100 [00:08<00:03,  7.64it/s]snpc.py:238 - Acc.......69.17, loss......0.1670\n",
      "Training Progress:  80%|████████  | 80/100 [00:09<00:02,  8.20it/s]snpc.py:238 - Acc.......69.17, loss......0.1651\n",
      "Training Progress:  90%|█████████ | 90/100 [00:10<00:01,  8.75it/s]snpc.py:238 - Acc.......69.17, loss......0.1634\n",
      "Training Progress: 100%|██████████| 100/100 [00:12<00:00,  8.30it/s]\n",
      "snpc.py:242 - Training finished\n"
     ]
    }
   ],
   "source": [
    "model = SNPC(2)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.95061728395062"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 1., ..., 0., 0., 1.],\n",
       "       [1., 2., 0., ..., 0., 0., 1.],\n",
       "       [2., 1., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [3., 1., 1., ..., 0., 0., 1.],\n",
       "       [1., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 1., 2., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48241512, 0.51758488],\n",
       "       [0.86735847, 0.13264153],\n",
       "       [0.73895017, 0.26104983],\n",
       "       [0.56193991, 0.43806009],\n",
       "       [0.81581809, 0.18418191],\n",
       "       [0.71137139, 0.28862861],\n",
       "       [0.89061764, 0.10938236],\n",
       "       [0.78400009, 0.21599991],\n",
       "       [0.61345124, 0.38654876],\n",
       "       [0.92671707, 0.07328293],\n",
       "       [0.34021818, 0.65978182],\n",
       "       [0.73891958, 0.26108042],\n",
       "       [0.87662346, 0.12337654],\n",
       "       [0.67855989, 0.32144011],\n",
       "       [0.94525281, 0.05474719],\n",
       "       [0.6983563 , 0.3016437 ],\n",
       "       [0.95420033, 0.04579967],\n",
       "       [0.86151099, 0.13848901],\n",
       "       [0.74373551, 0.25626449],\n",
       "       [0.88702616, 0.11297384],\n",
       "       [0.53826103, 0.46173897],\n",
       "       [0.94553739, 0.05446261],\n",
       "       [0.33727926, 0.66272074],\n",
       "       [0.77802233, 0.22197767],\n",
       "       [0.74411807, 0.25588193],\n",
       "       [0.80146798, 0.19853202],\n",
       "       [0.62822682, 0.37177318],\n",
       "       [0.86316867, 0.13683133],\n",
       "       [0.336008  , 0.663992  ],\n",
       "       [0.89243715, 0.10756285],\n",
       "       [0.70290191, 0.29709809],\n",
       "       [0.75531916, 0.24468084],\n",
       "       [0.71573835, 0.28426165],\n",
       "       [0.70096305, 0.29903695],\n",
       "       [0.67713198, 0.32286802],\n",
       "       [0.80696582, 0.19303418],\n",
       "       [0.9353416 , 0.0646584 ],\n",
       "       [0.6721699 , 0.3278301 ],\n",
       "       [0.30075525, 0.69924475],\n",
       "       [0.94729556, 0.05270444],\n",
       "       [0.88579297, 0.11420703],\n",
       "       [0.41539413, 0.58460587],\n",
       "       [0.67533305, 0.32466695],\n",
       "       [0.96350044, 0.03649956],\n",
       "       [0.36868997, 0.63131003],\n",
       "       [0.55928173, 0.44071827],\n",
       "       [0.57972845, 0.42027155],\n",
       "       [0.90543649, 0.09456351],\n",
       "       [0.73554715, 0.26445285],\n",
       "       [0.6750067 , 0.3249933 ],\n",
       "       [0.94060366, 0.05939634],\n",
       "       [0.92392873, 0.07607127],\n",
       "       [0.87631089, 0.12368911],\n",
       "       [0.94158859, 0.05841141],\n",
       "       [0.75787114, 0.24212886],\n",
       "       [0.37345419, 0.62654581],\n",
       "       [0.8370226 , 0.1629774 ],\n",
       "       [0.92779796, 0.07220204],\n",
       "       [0.95189509, 0.04810491],\n",
       "       [0.69318362, 0.30681638],\n",
       "       [0.28543343, 0.71456657],\n",
       "       [0.65108658, 0.34891342],\n",
       "       [0.57674737, 0.42325263],\n",
       "       [0.66116056, 0.33883944],\n",
       "       [0.87413156, 0.12586844],\n",
       "       [0.830115  , 0.169885  ],\n",
       "       [0.90592601, 0.09407399],\n",
       "       [0.54246912, 0.45753088],\n",
       "       [0.74747569, 0.25252431],\n",
       "       [0.68810153, 0.31189847],\n",
       "       [0.7256858 , 0.2743142 ],\n",
       "       [0.92779796, 0.07220204],\n",
       "       [0.64187518, 0.35812482],\n",
       "       [0.4425608 , 0.5574392 ],\n",
       "       [0.71436192, 0.28563808],\n",
       "       [0.66716377, 0.33283623],\n",
       "       [0.76179985, 0.23820015],\n",
       "       [0.93969254, 0.06030746],\n",
       "       [0.84915713, 0.15084287],\n",
       "       [0.34933373, 0.65066627],\n",
       "       [0.62242778, 0.37757222],\n",
       "       [0.77753591, 0.22246409],\n",
       "       [0.29160504, 0.70839496],\n",
       "       [0.60314777, 0.39685223],\n",
       "       [0.8479931 , 0.1520069 ],\n",
       "       [0.82875645, 0.17124355],\n",
       "       [0.57702716, 0.42297284],\n",
       "       [0.81244367, 0.18755633],\n",
       "       [0.3147122 , 0.6852878 ],\n",
       "       [0.931335  , 0.068665  ],\n",
       "       [0.79598369, 0.20401631],\n",
       "       [0.12342682, 0.87657318],\n",
       "       [0.56276137, 0.43723863],\n",
       "       [0.92779796, 0.07220204],\n",
       "       [0.91321092, 0.08678908],\n",
       "       [0.66990867, 0.33009133],\n",
       "       [0.90826282, 0.09173718],\n",
       "       [0.31063643, 0.68936357],\n",
       "       [0.80111109, 0.19888891],\n",
       "       [0.88579297, 0.11420703],\n",
       "       [0.86243428, 0.13756572],\n",
       "       [0.9026445 , 0.0973555 ],\n",
       "       [0.7936642 , 0.2063358 ],\n",
       "       [0.82644031, 0.17355969],\n",
       "       [0.92194388, 0.07805612],\n",
       "       [0.80688661, 0.19311339],\n",
       "       [0.74373551, 0.25626449],\n",
       "       [0.36012497, 0.63987503],\n",
       "       [0.58327065, 0.41672935],\n",
       "       [0.92486587, 0.07513413],\n",
       "       [0.5395525 , 0.4604475 ],\n",
       "       [0.7303531 , 0.2696469 ],\n",
       "       [0.93945689, 0.06054311],\n",
       "       [0.19327897, 0.80672103],\n",
       "       [0.54747954, 0.45252046],\n",
       "       [0.60989648, 0.39010352],\n",
       "       [0.79359096, 0.20640904],\n",
       "       [0.69548612, 0.30451388],\n",
       "       [0.63014332, 0.36985668],\n",
       "       [0.75077557, 0.24922443],\n",
       "       [0.24923649, 0.75076351],\n",
       "       [0.48645781, 0.51354219],\n",
       "       [0.72065414, 0.27934586],\n",
       "       [0.66990867, 0.33009133],\n",
       "       [0.71780013, 0.28219987],\n",
       "       [0.75473096, 0.24526904],\n",
       "       [0.79872343, 0.20127657],\n",
       "       [0.6807363 , 0.3192637 ],\n",
       "       [0.92779796, 0.07220204],\n",
       "       [0.5395525 , 0.4604475 ],\n",
       "       [0.89790179, 0.10209821],\n",
       "       [0.54302094, 0.45697906],\n",
       "       [0.63237957, 0.36762043],\n",
       "       [0.55315411, 0.44684589],\n",
       "       [0.71849056, 0.28150944],\n",
       "       [0.62395098, 0.37604902],\n",
       "       [0.85550417, 0.14449583],\n",
       "       [0.931335  , 0.068665  ],\n",
       "       [0.34933373, 0.65066627],\n",
       "       [0.92825227, 0.07174773],\n",
       "       [0.83923097, 0.16076903],\n",
       "       [0.86441867, 0.13558133],\n",
       "       [0.86435899, 0.13564101],\n",
       "       [0.89695433, 0.10304567],\n",
       "       [0.50538209, 0.49461791],\n",
       "       [0.6498893 , 0.3501107 ],\n",
       "       [0.80698292, 0.19301708],\n",
       "       [0.91930106, 0.08069894],\n",
       "       [0.69562449, 0.30437551],\n",
       "       [0.95524053, 0.04475947],\n",
       "       [0.46330469, 0.53669531],\n",
       "       [0.79761866, 0.20238134],\n",
       "       [0.75537174, 0.24462826],\n",
       "       [0.80146798, 0.19853202],\n",
       "       [0.77842972, 0.22157028],\n",
       "       [0.69267154, 0.30732846],\n",
       "       [0.63894207, 0.36105793],\n",
       "       [0.92955868, 0.07044132],\n",
       "       [0.69812231, 0.30187769],\n",
       "       [0.5775484 , 0.4224516 ],\n",
       "       [0.93585959, 0.06414041],\n",
       "       [0.79381085, 0.20618915],\n",
       "       [0.5624263 , 0.4375737 ],\n",
       "       [0.89724115, 0.10275885],\n",
       "       [0.77052817, 0.22947183],\n",
       "       [0.67546884, 0.32453116],\n",
       "       [0.94073083, 0.05926917],\n",
       "       [0.74044592, 0.25955408],\n",
       "       [0.89061764, 0.10938236],\n",
       "       [0.86364644, 0.13635356],\n",
       "       [0.56589405, 0.43410595],\n",
       "       [0.60811494, 0.39188506],\n",
       "       [0.28046205, 0.71953795],\n",
       "       [0.51049222, 0.48950778],\n",
       "       [0.73306567, 0.26693433],\n",
       "       [0.70134699, 0.29865301],\n",
       "       [0.533987  , 0.466013  ],\n",
       "       [0.62242778, 0.37757222],\n",
       "       [0.93544598, 0.06455402],\n",
       "       [0.84919858, 0.15080142]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lvq_base.py:156 - Starting 5-fold cross-validation\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......73.38, loss......0.2440\n",
      "Training Progress:  10%|█         | 10/100 [00:00<00:08, 10.59it/s]snpc.py:238 - Acc.......71.98, loss......0.1997\n",
      "Training Progress:  20%|██        | 20/100 [00:01<00:07, 10.48it/s]snpc.py:238 - Acc.......70.73, loss......0.1879\n",
      "Training Progress:  30%|███       | 30/100 [00:02<00:06, 10.32it/s]snpc.py:238 - Acc.......70.89, loss......0.1797\n",
      "Training Progress:  40%|████      | 40/100 [00:03<00:05, 10.61it/s]snpc.py:238 - Acc.......70.11, loss......0.1735\n",
      "Training Progress:  50%|█████     | 50/100 [00:04<00:04, 11.28it/s]snpc.py:238 - Acc.......69.95, loss......0.1690\n",
      "Training Progress:  60%|██████    | 60/100 [00:05<00:04,  8.42it/s]snpc.py:238 - Acc.......70.11, loss......0.1646\n",
      "Training Progress:  69%|██████▉   | 69/100 [00:06<00:03, 10.24it/s]snpc.py:238 - Acc.......69.80, loss......0.1608\n",
      "Training Progress:  79%|███████▉  | 79/100 [00:07<00:01, 11.13it/s]snpc.py:238 - Acc.......69.80, loss......0.1579\n",
      "Training Progress:  89%|████████▉ | 89/100 [00:08<00:01, 10.82it/s]snpc.py:238 - Acc.......69.49, loss......0.1556\n",
      "Training Progress: 100%|██████████| 100/100 [00:09<00:00, 10.43it/s]\n",
      "snpc.py:242 - Training finished\n",
      "lvq_base.py:179 - Fold 1: Accuracy = 0.6973\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......73.14, loss......0.2385\n",
      "Training Progress:  10%|█         | 10/100 [00:00<00:07, 11.35it/s]snpc.py:238 - Acc.......73.14, loss......0.1953\n",
      "Training Progress:  20%|██        | 20/100 [00:01<00:06, 11.67it/s]snpc.py:238 - Acc.......72.33, loss......0.1873\n",
      "Training Progress:  30%|███       | 30/100 [00:02<00:05, 11.77it/s]snpc.py:238 - Acc.......72.33, loss......0.1819\n",
      "Training Progress:  40%|████      | 40/100 [00:03<00:05, 10.44it/s]snpc.py:238 - Acc.......71.35, loss......0.1769\n",
      "Training Progress:  50%|█████     | 50/100 [00:04<00:04, 11.13it/s]snpc.py:238 - Acc.......71.35, loss......0.1726\n",
      "Training Progress:  60%|██████    | 60/100 [00:05<00:03, 11.78it/s]snpc.py:238 - Acc.......71.19, loss......0.1692\n",
      "Training Progress:  70%|███████   | 70/100 [00:06<00:02, 11.52it/s]snpc.py:238 - Acc.......71.02, loss......0.1668\n",
      "Training Progress:  80%|████████  | 80/100 [00:07<00:01, 11.71it/s]snpc.py:238 - Acc.......70.86, loss......0.1654\n",
      "Training Progress:  90%|█████████ | 90/100 [00:07<00:00, 11.39it/s]snpc.py:238 - Acc.......70.54, loss......0.1641\n",
      "Training Progress: 100%|██████████| 100/100 [00:08<00:00, 11.46it/s]\n",
      "snpc.py:242 - Training finished\n",
      "lvq_base.py:179 - Fold 2: Accuracy = 0.6644\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......72.23, loss......0.2452\n",
      "Training Progress:  10%|█         | 10/100 [00:00<00:07, 12.25it/s]snpc.py:238 - Acc.......71.44, loss......0.1933\n",
      "Training Progress:  20%|██        | 20/100 [00:01<00:07, 11.28it/s]snpc.py:238 - Acc.......69.24, loss......0.1788\n",
      "Training Progress:  30%|███       | 30/100 [00:02<00:06, 10.89it/s]snpc.py:238 - Acc.......69.24, loss......0.1697\n",
      "Training Progress:  40%|████      | 40/100 [00:03<00:07,  8.01it/s]snpc.py:238 - Acc.......69.71, loss......0.1636\n",
      "Training Progress:  50%|█████     | 50/100 [00:05<00:06,  8.09it/s]snpc.py:238 - Acc.......69.55, loss......0.1590\n",
      "Training Progress:  60%|██████    | 60/100 [00:06<00:04,  8.93it/s]snpc.py:238 - Acc.......69.39, loss......0.1555\n",
      "Training Progress:  70%|███████   | 70/100 [00:07<00:02, 10.33it/s]snpc.py:238 - Acc.......69.39, loss......0.1525\n",
      "Training Progress:  79%|███████▉  | 79/100 [00:08<00:02,  8.84it/s]snpc.py:238 - Acc.......69.08, loss......0.1498\n",
      "Training Progress:  89%|████████▉ | 89/100 [00:09<00:01, 10.89it/s]snpc.py:238 - Acc.......68.76, loss......0.1474\n",
      "Training Progress: 100%|██████████| 100/100 [00:10<00:00,  9.78it/s]\n",
      "snpc.py:242 - Training finished\n",
      "lvq_base.py:179 - Fold 3: Accuracy = 0.7217\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......74.15, loss......0.2279\n",
      "Training Progress:  10%|█         | 10/100 [00:00<00:08, 10.68it/s]snpc.py:238 - Acc.......74.15, loss......0.1875\n",
      "Training Progress:  20%|██        | 20/100 [00:01<00:08,  9.99it/s]snpc.py:238 - Acc.......72.65, loss......0.1756\n",
      "Training Progress:  30%|███       | 30/100 [00:02<00:06, 10.69it/s]snpc.py:238 - Acc.......72.15, loss......0.1673\n",
      "Training Progress:  40%|████      | 40/100 [00:03<00:05, 10.81it/s]snpc.py:238 - Acc.......71.81, loss......0.1612\n",
      "Training Progress:  50%|█████     | 50/100 [00:04<00:04, 11.02it/s]snpc.py:238 - Acc.......71.48, loss......0.1563\n",
      "Training Progress:  60%|██████    | 60/100 [00:05<00:03, 10.65it/s]snpc.py:238 - Acc.......71.48, loss......0.1525\n",
      "Training Progress:  70%|███████   | 70/100 [00:06<00:02, 10.87it/s]snpc.py:238 - Acc.......71.15, loss......0.1496\n",
      "Training Progress:  80%|████████  | 80/100 [00:07<00:01, 11.01it/s]snpc.py:238 - Acc.......71.15, loss......0.1473\n",
      "Training Progress:  90%|█████████ | 90/100 [00:08<00:00, 10.95it/s]snpc.py:238 - Acc.......71.15, loss......0.1453\n",
      "Training Progress: 100%|██████████| 100/100 [00:09<00:00, 10.74it/s]\n",
      "snpc.py:242 - Training finished\n",
      "lvq_base.py:179 - Fold 4: Accuracy = 0.6684\n",
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......74.08, loss......0.2424\n",
      "Training Progress:  10%|█         | 10/100 [00:00<00:08, 11.18it/s]snpc.py:238 - Acc.......72.32, loss......0.1938\n",
      "Training Progress:  20%|██        | 20/100 [00:01<00:07, 10.92it/s]snpc.py:238 - Acc.......71.84, loss......0.1835\n",
      "Training Progress:  30%|███       | 30/100 [00:02<00:06, 11.10it/s]snpc.py:238 - Acc.......70.57, loss......0.1771\n",
      "Training Progress:  40%|████      | 40/100 [00:03<00:05, 10.72it/s]snpc.py:238 - Acc.......69.93, loss......0.1714\n",
      "Training Progress:  50%|█████     | 50/100 [00:04<00:04, 11.20it/s]snpc.py:238 - Acc.......69.13, loss......0.1670\n",
      "Training Progress:  60%|██████    | 60/100 [00:05<00:03, 11.37it/s]snpc.py:238 - Acc.......69.13, loss......0.1636\n",
      "Training Progress:  70%|███████   | 70/100 [00:06<00:02, 10.49it/s]snpc.py:238 - Acc.......69.13, loss......0.1609\n",
      "Training Progress:  80%|████████  | 80/100 [00:07<00:01, 11.04it/s]snpc.py:238 - Acc.......69.13, loss......0.1583\n",
      "Training Progress:  90%|█████████ | 90/100 [00:08<00:00, 11.22it/s]snpc.py:238 - Acc.......68.97, loss......0.1555\n",
      "Training Progress: 100%|██████████| 100/100 [00:09<00:00, 10.92it/s]\n",
      "snpc.py:242 - Training finished\n",
      "lvq_base.py:179 - Fold 5: Accuracy = 0.6746\n",
      "lvq_base.py:183 - Accuracies: [0.6972789115646258, 0.6643990929705216, 0.721655328798186, 0.6683673469387755, 0.6746031746031746]\n",
      "lvq_base.py:184 - Mean Accuracy: 0.6852607709750567\n",
      "lvq_base.py:185 - Accuracy Variance: 0.00046063625752644163\n",
      "lvq_base.py:187 - Finished Cross Validation\n"
     ]
    }
   ],
   "source": [
    "model.cross_validate(x_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]snpc.py:238 - Acc.......61.17, loss......0.3424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [00:00<00:03, 23.36it/s]snpc.py:238 - Acc.......72.10, loss......0.2009\n",
      "Training Progress:  18%|█▊        | 18/100 [00:00<00:03, 24.80it/s]snpc.py:238 - Acc.......69.81, loss......0.2003\n",
      "Training Progress:  30%|███       | 30/100 [00:01<00:02, 25.72it/s]snpc.py:238 - Acc.......68.79, loss......0.2007\n",
      "Training Progress:  39%|███▉      | 39/100 [00:01<00:02, 25.11it/s]snpc.py:238 - Acc.......68.79, loss......0.1992\n",
      "Training Progress:  48%|████▊     | 48/100 [00:01<00:01, 26.18it/s]snpc.py:238 - Acc.......68.79, loss......0.1971\n",
      "Training Progress:  60%|██████    | 60/100 [00:02<00:01, 26.53it/s]snpc.py:238 - Acc.......68.79, loss......0.1948\n",
      "Training Progress:  69%|██████▉   | 69/100 [00:02<00:01, 25.42it/s]snpc.py:238 - Acc.......69.30, loss......0.1925\n",
      "Training Progress:  78%|███████▊  | 78/100 [00:03<00:00, 24.77it/s]snpc.py:238 - Acc.......69.30, loss......0.1902\n",
      "Training Progress:  90%|█████████ | 90/100 [00:03<00:00, 26.54it/s]snpc.py:238 - Acc.......69.30, loss......0.1875\n",
      "Training Progress: 100%|██████████| 100/100 [00:03<00:00, 25.51it/s]\n",
      "snpc.py:242 - Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.77777777777777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try for mean initialization\n",
    "trained_model = SNPC(num_prototypes_per_class=1, initialization_type='random')\n",
    "trained_model.fit(x_train, y_train)\n",
    "trained_model.evaluate(x_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
